> 此文档由OpenAI GPT-4辅助生成，参考[链接](https://chat.openai.com/)
# GPT4DST项目完整方案
![BG](../../assets/DSTBG_1.png )
## 项目概述
<!-- ![BG](../assets/logo_1.jpg) -->
### 背景

GPT4DST是一个基于langchain库调用OpenAI的GPT闭源模型的LLM二次开发应用。该项目旨在为DST（饥荒联机版）游戏提供智能互动体验，通过开发专门的模组与玩家交互。

### 目标

- 开发基于GPT模型的智能交互模组，集成到DST游戏中。
- 在阿里云ECS上部署应用并发布API接口，供游戏模组调用。
- 实现与玩家的自然语言交互，提升游戏体验。

## 方案设计

### 技术栈

- **编程语言**：Python（主要应用开发）、Lua（DST模组开发）
- **框架和库**：langchain（调用OpenAI GPT模型）、FastAPI（API服务）
- **代码协作工具**：GitHub
- **服务器环境**：阿里云ECS（Elastic Compute Service）

### 架构设计（参考）

本项目包括两个主要部分：基于Python的后端服务，和基于Lua的DST游戏模组。后端服务负责处理与GPT模型的交互和逻辑处理，游戏模组负责与玩家交互并调用后端API获取响应。

```
GPT4DST/
│
├── app/ # 应用主目录
│ ├── init.py # 初始化应用
│ ├── main.py # FastAPI应用实例和路由
│ ├── dependencies.py # 定义依赖项
│ ├── models.py # 数据模型定义
│ ├── schemas.py # 请求和响应模型
│ ├── crud.py # 数据库CRUD操作
│ └── routers/ # 路由目录
│   ├── init.py
│   ├── interaction.py # DST互动接口路由
│   └── ... # 其他路由文件
│
├── tests/ # 测试目录
│ ├── init.py
│ ├── test_main.py # 主要测试文件
│ └── ... # 其他测试文件
│
├── docs/ # 文档目录
│
├── .env # 环境变量文件
├── .gitignore # Git忽略文件
├── requirements.txt # 项目依赖
├── Dockerfile # Docker配置文件
├── docker-compose.yml # Docker compose配置（可选）
└── README.md # 项目README
```

<details>
<summary>查看详细说明</summary>

- **app/**: 应用程序的核心目录，包含所有主要的Python代码。
  - **main.py**: 定义FastAPI应用实例和路由，是应用的入口点。
  - **dependencies.py**: 定义项目所需的依赖项，例如数据库连接和查询参数。
  - **models.py**: 定义数据模型，通常用于ORM。
  - **schemas.py**: 定义请求和响应的Pydantic模型，用于数据验证和序列化。
  - **crud.py**: 定义对数据库的CRUD操作，用于抽象化数据库交互。
  - **routers/**: 存放定义各种API路由的文件，例如`interaction.py`负责处理与DST互动相关的API路由。

- **tests/**: 包含针对应用程序的单元测试和集成测试的目录。

- **docs/**: 存放项目文档的目录，可以包含使用Sphinx生成的文档。

- **.env**: 包含不应公开的环境变量，如API密钥和数据库URI。

- **requirements.txt**: 列出了所有项目依赖，可以通过`pip install -r requirements.txt`安装。

- **Dockerfile** 和 **docker-compose.yml**: 用于容器化应用和服务，简化部署流程。

- **README.md**: 提供项目概览，安装和使用指南，以及贡献说明。

</details>

### 接口设计

API将提供以下端点：

- `/interact`：接收游戏中的玩家输入，返回GPT模型的响应。

  - **方法**：POST
  - **参数**：
    - `player_input`: 玩家在游戏中的输入
  - **返回值**：
    - `model_response`: GPT模型基于玩家输入的响应

## 开发和协作流程

见同目录下此[文档](./项目协作手册.md)

## 部署和发布

### 服务器配置

- 选择阿里云ECS实例，如ecs.g5.large，安装Ubuntu 20.04，确保有足够的存储和带宽满足需求。

### 部署流程

- 设置阿里云ECS实例，安装必要的环境和依赖。
- ~~从GitHub拉取最新的`main`分支代码到ECS实例。~~
- ~~使用Uvicorn作为ASGI服务器，配合Nginx作为反向代理服务器，部署FastAPI应用。~~
- 设置环境变量，包括OpenAI的API密钥等。

### 持续集成/持续部署（CI/CD）

- ~~配置GitHub Actions，实现代码合并到`main`分支时自动部署到阿里云ECS。~~

## 风险管理

### 风险识别

- OpenAI GPT模型调用限制和成本。
- 游戏模组与后端服务的网络延迟和稳定性。

### 风险应对

- 优化API调用频率，引入缓存机制。
- 选择合适的ECS实例，确保与游戏服务器的良好连接。

## 附录

### A. 术语表

- **LLM**：Large Language Model，大型语言模型
- **DST**：Don't Starve Together，饥荒联机版
- **API**：Application Programming Interface，应用程序编程接口

### B. 参考材料

- [OpenAI](https://openai.com)
- [langchain官方文档](https://python.langchain.com/docs/)
- [FastAPI官方文档](https://fastapi.tiangolo.com/)
